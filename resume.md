# Web前端程序员简历模板

本简历模板由国内首家互联网人才拍卖网站「 [JobDeer.com](http://www.jobdeer.com) 」提供。

（括号里的是我们的顾问编写的说明，建议在简历书写完成后统一删除）

## 先讲讲怎样才是一份好的技术简历

首先，一份好的简历不光说明事实，更通过FAB模式来增强其说服力。

 - Feature：是什么
 - Advantage：比别人好在哪些地方
 - Benefit：如果雇佣你，招聘方会得到什么好处 

其次，写简历和写议论文不同，过分的论证会显得自夸，反而容易引起反感，所以要点到为止。这里的技巧是，提供论据，把论点留给阅读简历的人自己去得出。放论据要具体，最基本的是要数字化，好的论据要让人印象深刻。

举个例子，下边内容是虚构的：

2006年，我参与了手机XX网发布系统WAPCMS的开发（```这部分是大家都会写的```）。作为核心程序员，我不但完成了网站界面、调度队列的开发工作，更提出了高效的组件级缓存系统，通过碎片化缓冲有效的提升了系统的渲染效率。（```这部分是很多同学忘掉的，要写出你在这个项目中具体负责的部分，以及你贡献出来的价值。```）在该系统上线后，Web前端性能从10QPS提升到200QPS，服务器由10台减少到3台（``` 通过量化的数字来增强可信度 ```）。2008年我升任WAPCMS项目负责人，带领一个3人小组支持着每天超过2亿的PV（``` 这就是Benefit。你能带给前雇主的价值，也就是你能带给新雇主的价值。 ```）。

有同学问，如果我在项目里边没有那么显赫的成绩可以说怎么办？讲不出成绩时，就讲你的成长。因为学习能力也是每家公司都看中的东西。你可以写你在这个项目里边遇到了一个什么样的问题，别人怎么解决的，你怎么解决的，你的方案好在什么地方，最终这个方案的效果如何。

具体、量化、有说服力，是技术简历特别需要注重的地方。

（以上内容在写完简历后，对每一段进行评估，完成后再删除）

---


# 联系方式
（HR会打印你的简历，用于在面试的时候联系，所以联系方式放到最上边会比较方便）

- 手机：13311369059 （```如果是外地手机，可注明。如经常关机，要写上最优联系时间```）
- Email：leontian1024@gmail.com（```虽然我觉得QQ邮箱无所谓，不过有些技术人员比较反感，建议用G```）
- 微信号：13311369059 ( 与手机号相同 )（```提供一个通过网络可以联系到你的方式```）

---

# 个人信息

 - 田昕峣 / 男 / 1997  
 - 本科 / 北京工业大学  国家示范性软件学院  软件工程( 实验班 )
 - 工作经验：半年( 实习岗位 )
 - CSDN 技术博客：https://blog.csdn.net/weixin_38070561 ( ``` 使用GitHub Host的Big较高 ```  )
 - 知乎技术专栏及个人主页: https://www.zhihu.com/people/winchester-26/activities
 - Github：https://github.com/XinyaoTian( ``` 有原创repo的Github帐号会极大的提升你的个人品牌 ```  )
 - 私人 Git 服务器——用于储藏自己的点点滴滴：[田同学的私人 Git 服务器](http://proxy.smartian.net:10300)

 - 期望职位：Docker 工程师、Kubernetes 工程师、Go语言工程师
 - 期望薪资：税前月薪15k-20k
 - 期望城市：北京

---

# 工作经历
（工作经历按逆序排列，最新的在最前边，按公司做一级分组，公司内按二级分组）

## 中国科学院软件研究所  ( 2018 年 12 月 至今 )

### 基于 Kubernetes 的微服务监控数据可视化项目 ( 王焘导师 “企业云” 项目组 )
> 技能关键词: 项目研究, 企业级应用开发, Web 程序开发, 云主机(阿里云), 微服务架构, Kubernetes(K8s), docker, ServiceMesh, Istio, Envoy, Linux(Ubuntu)

由于在校期间取得了较为优秀的学习成绩和校级学习优秀奖学金，故本人荣幸地获得了参与国家级毕业设计项目的机会。

本项目组的主要工作是基于 Kubernetes 研究及开发某互联网企业的自用云服务平台( 类似“阿里云”、“腾讯云”等 )并按时交付。作为项目组的一员，我主要负责研究“微服务架构如何应用在 Kubernetes 集群”以及设计实现 Docker 容器监控云件及模块。

在该项目的研究中，我查阅并翻译了数篇外文博客及外文开发文档，在自己得到提高的同时也为中文开发社区贡献了便利和价值( 翻译文章见: [Envoy 、 Nginx 和 HAProxy，微服务中的通信代理该如何抉择? 翻译自英文博客](https://zhuanlan.zhihu.com/p/53470343) ，首发于掘金翻译计划 )。技术选型方面，我使用了“服务网格(  Service Mesh )”架构来代替较为流行的“ Spring Cloud 框架”进行监控模块的设计。目前该模块的进度已经可以监测到每一个微服务之间的调用关系( 基于 Istio 的 Sidecar 模式和 L4 、 L7 代理 )，以及可视化展现多种常用监测指标( 如 CPU 利用率、网络延迟等，基于 Prometheus 和 Grafana )。项目负责人，中科院的博士生导师王焘教授对我目前的工作非常满意。

我相信，如果该项目有朝一日投入实际生产环境，将会极大地改善开发人员的开发工作流程、同时减轻运维人员的工作量。


 注: 由于本人对本专业兴趣浓厚，因此于大三便已修完本科全部学分。为避免虚度时光，同时丰富社会阅历、让自己得到实际的开发及工作经验，本人于 2018 年 4 月 至 2018 年 11 月 期间，在清华科技园内寻得多份实习工作，磨练自我。
## 清数教育 ( 2018 年 9 月 至 2018 年 11 月 )

### 北京大学-医学博士 “牙周病辅助诊疗系统” 合作项目
> 技能关键词: 项目开发, Web 程序开发, 云主机(阿里云), 机器学习, spark, pyspark, Zeppelin, docker, python, Flask, Linux(Ubuntu)
[项目Web部分内容](https://github.com/XinyaoTian/dentist_demo)

北京大学医学博士与本公司的 “牙周病辅助诊疗系统” 合作项目，包括模型训练、网站系统设计及系统 Demo 版本的实现( 配合 PPT 用于进行专家组答辩时的演示 )

近年来，大数据的跨领域研究受到热烈追捧。本项目由北京大学一名研究牙周病的医学博士发起，提供近 20年来其部门大夫出诊时所收集到的 170 余万条真实临床牙周病人的牙位点数据( 共 27 个纬度 )，并由我司负责机器学习的训练建模部分( 包括数据清洗、预处理、可视化、机器学习建模、模型调参及验证、模型导出及持久化 )和一个具有“输入新的病人数据并预测其牙周病严重程度”功能的 Web 服务原型的开发。

该项目由本人全权负责。作为该项目的负责人，我需要保证开发进度和模型及系统质量；与此同时，还必须亲自与北京大学医学博士保持密切的联系和沟通，这是我在以往的任何项目经理中都鲜有遇到过的。从最初与博士建立联系与沟通、到明确需求并数次向其展示我的计划使用的训练方案及系统设计方案、再到搭建实时在线协同开发环境、直至最后成功训练出符合要求的模型并将其整合进系统 Demo 版本、甚至最后的 PPT 制作以及亲自面对专家组的答辩，这一连串紧促但完整的项目流程使我真真切切地体会到了一个项目从构想到落地过程之间的艰辛。

技术选型方面，模型训练平台我选用的是 Zeppelin，配合底层的 Spark 和 pyspark 工具库可以达到非常优秀的可视化和实时交流协作的目的。几乎每次跑完一个模型，我都可以立刻使用 Zeppelin 将网格搜索交叉验证的结果向博士在线汇报，这种频繁的“汇报-改进”模式能够及时发现问题并立刻作出修改，极大地避免了“开发和需求偏差过大”的风险。Web 服务方面，由于是开发演示版 Demo ，对性能要求不高，且需求较为明确，因此本人选用基于 Python 的 Flask 框架，简单易用，加快开发进度。Web 服务通过 pyspark 调用存储在 hdfs 上训练好的模型来实现“新值预测”的功能。

项目完成后，博士和公司领导对我的工作给予高度评价；我开发的 Web 服务演示版在答辩时获得了专家组老师们的青睐，有一名专家甚至多次输入了牙位点的各种数值，并将预测结果与其实际临床经验对比，发现仅有微小出入，便对本系统和机器学习模型产生了浓厚兴趣。

作为本项目的负责人，我还荣幸地成为了该博士论文的作者之一。该论文已投稿给国内某顶级医疗领域期刊，有望在明年发表。


### 网易云课堂 “学员在线 GPU 实训平台” 项目
> 技能关键词: 项目开发, Web 程序开发, 云主机(阿里云), Kubernetes(K8s), docker, Linux(Ubuntu), Nvidia CUDA
[“网易云课堂”课程链接](https://study.163.com/provider/400000000325043/index.htm)

网易云课堂 “AI 工程师” 及 “深度学习工程师” 两门课程的 “学员在线 GPU 实训平台” 项目的部分设计及搭建。就目前( 2018 年底 )的情况而言，支持容器模型调度 GPU 资源的容器管理框架只有 Kubernetes ，故在该项目的设计阶段我们( 本项目组成员 )就一致决定基于 Kuberenetes 来实现学员在线 GPU 实训平台。

在此项目中，我负责查阅及研究 Kubernetes 的英文官方文档，并根据以往搭建 CPU 实训平台的经验，针对学员的操作行为进行容器及 Web 服务流程的生命周期设计( 包括：开始及关闭实验、实验环境加密、实验环境跳转等模块 )。在完成了 Kubernetes 对于 GPU 调度的知识积累和流程设计后，我选用了公司租用的三台阿里云主机，进行了实验集群的搭建、代码实现及测试；并由开发团队依照本实验集群的原型进行具体开发。

该项目与网易云课堂的两门课程同时上线，使学员能够在学习网课时跳过繁琐的本地软件安装步骤，直接开始敲代码做实验，从而提升学习效率。此外，由于该项目基于 Kubernetes 架构，不仅可以在操作系统层级上实现学员实验环境的隔离，而且还能实现 GPU 资源池的动态扩容和缩容，在学员使用的高峰时段( 大约 100 名学员同时利用 GPU 资源 )依然能够保证该平台的稳定性。

我将本项目中查阅到的重要博客和资料都翻译为中文并发布到了我的 csdn 博客上，以供公司项目组其他成员和广大国内开发者查阅。

该平台在课程期间为学员持续地提供了稳定的服务。实验集群的原型和我的翻译文献获得了项目组成员们的肯定；本项目上线使用后获得了项目负责人和公司领导的一致好评，并准备为下一期云课堂继续使用。



### 清数教育 “高校在线实训云平台” 项目
> 技能关键词: 项目开发, Web 程序开发, 云主机(阿里云), Kubernetes(K8s), docker, docker hub, Linux(Ubuntu), REST api
[项目网站](http://lab.tsingdataedu.com/xnslab.html)

清数教育 “高校云端实训平台” 项目的部分设计及搭建。

高校的计算机相关专业，为了供学生做上机实验，校方通常要赤巨资购买大量硬件设备；而实际上这些机器的使用效率很低且过几年就会被淘汰。这是对教育资源非常严重的浪费。

本项目主要针对上述情况，为节省校方开销、同时提高计算资源的利用率，而开发的高校在线实训云平台。我在该项目中主要负责“用于学生实验环境的 docker 镜像( docker image )”的制作、学生操作流程生命周期的设计及平台原型的实现。该项目可以通过 REST api 调用的方式，根据不同课程启动不同配置和安装了不同工具库的实验环境，按需分配实验资源，使学生们不用再在指定的时间去机房，随时随地打开浏览器就可以进行自己的课程实验。

我在研究及开发本系统原型时收获颇丰：查阅了 docker 文档及大量有关 docker 的技术博客、掌握了 docker hub 以及搭建公司内部镜像服务器的方法、熟悉了容器架构以及基于容器架构的开发流程、还基本掌握了 docker 命令及其使用方法。通过 Rest api 使各个模块利用公网 ip 在不同主机上独立工作是最让我感到有价值的地方。

该云平台在同年 11 月 2 日位于天津科技大学举办的“高校大数据研修班 第二期”的实训环节中，承受住了数百位高校老师同时在线使用的压力，保证了使用的流畅性和体验，并被老师们连连称赞非常好用。我制作的 docker 镜像和“基于 api 启动不同配置的镜像”得到了项目负责人的肯定，也得到了老师们的赞赏。在本人离开公司之际，已经有三所高校购买了该云平台为其学生提供在线实验服务。

 
## 大数据文摘 ( 2018 年 7 月 至 2018 年 9 月 )

### 清华大学-数据科学研究院 “ 2018 年度顶级数据团队建设全景报告” 合作项目
> 技能关键词: 项目开发, 团队管理, python, pandas, scrapy, git, jieba, NoSQL(mongoDB), hdfs
[“清华2018顶级数据团队建设全景报告-摘要版”  附“精华版”下载链接](https://t.cj.sina.com.cn/articles/view/6105753431/16bee675701900bt98)
也可谷歌或百度直接搜索“2018 年度顶级数据团队建设全景报告”，数十家科技媒体争先报道

本项目由清华大学数据科学研究院主办，《大数据文摘》协办。其团队组成主要由以下四个团队所组成：负责获取数据的“爬虫团队”，负责分析数据的“分析团队”，负责撰写文章及采访各位业内大牛的“媒体团队”和负责版面设计、印刷及发布会的“设计团队”。团队总人数多达数十人。

在该项目中，我同时担任了“爬虫团队”的副组长和“分析团队”的负责人。在“爬虫团队”中，由于该团队总人数达 13 人之多，为了统一数据格式、避免数据过于混乱，我负责协助拟定“爬虫数据获取维度及规范”，以符合发布需求；同时，我还单独负责获取“智联招聘”网站上有关数据岗位的职位信息。在“分析团队”中，结合获取到的数据，我负责选定分析工具( 选用 pandas 工具库，并自己对于 jieba 做了一层封装供组员快速使用 )、组织并协调分析团队的成员、拟定哪些维度需要分析并明确分析目的；同时我还与“设计团队”的成员多次开会，讨论设计方案的可行性、明确“分析团队”的分析结果输出格式等。

在团队全体成员连续三周的努力下，“ 2018 年度顶级数据团队建设全景报告” 于 2018 年 9 月 26 日在清华大学数据科学研究院报告厅成功发布，发布会现场气氛热烈。在本报告发布后，包括“机器之心”、“数据堂”、“数据派”、“上海大数据联盟”、“数字人才”( 当然也包括“大数据文摘” )在内的数十个公众号( 包括十余个百万量级的公众号 )在当日或次日也立即进行了转载；科技圈公众号被同一份报告如此大规模“屠版”的现象实属罕见。




### 《Python 实战案例》书籍写作
> 技能关键词: 书籍写作, 计算机网络知识, python, scrapy, xpath 路径表达式, 正则表达式, html, css, Linux(Ubuntu)

受北京邮电大学一教导主任委托，《大数据文摘》开始写作并计划出版一本供计算机相关专业学生阅读的课外读物《 Python 实战案例 》。

我在其中负责“爬虫数据获取”及“数据分析”这两个章节的写作。由于我本人就是学生，并且结合自己的开发和写作经验，我在“爬虫数据获取”简要介绍了爬虫的定义、爬虫的用途；较为详尽的阐述了 Scrapy 的架构及各部分模块的功能；在章节最后我将自己的“链家网”爬虫代码进行了整理修改并作出详尽的注释，作为课后习题的参考答案。

在“数据分析”章节，我主要阐述了数据分析的定义、目的、常用方法和工具库。在章节的最后，我将曾与别人合作过的“链家网”房源信息分析及可视化的代码改编为许多小题，并附以逐行详尽的注释作为参考答案。

利用在线作图工具 ProcessOn，我亲自为这两个章节画了将近十余幅图以辅助各章节的文字内容，以求做到图文并茂，力争让将来看到这本书的同学们能深入理解这两个章节的内容，并发自内心地感觉有趣。

我的写作内容在提交初稿后经历了 3 次修改，最终得到了本书编辑和技术审核的高度评价。本书预计将由清华大学出版社于 2019 年底出版，希望获得广大学子的青睐，并提出宝贵的x指导意见。


我在此项目负责了哪些工作，分别在哪些地方做得出色/和别人不一样/成长快，这个项目中，我最困难的问题是什么，我采取了什么措施，最后结果如何。这个项目中，我最自豪的技术细节是什么，为什么，实施前和实施后的数据对比如何，同事和领导对此的反应如何。


### 其他项目

### “大数据职位预测分析” 项目
> 技能关键词: 项目开发, Web 程序开发, jupyter notebook, pyspark, spark, python, Flask

利用《大数据文摘》公众号中“职位情报局”栏目中搜集的各种职位数据，我使用 Jupyter 配合 pyspark 工具库对上万条职位数据进行了机器学习建模。在一个简单的模型被训练好后，我使用 Flask 开发了一个具有“输入自身条件并预测薪资”的 Web 服务 Demo 版本。

公司领导对我的想法和开发出来的 Web 服务给予了鼓励。而且这个 Demo 在公司的同事间甚至还流行了几天，大家都对于自己预测出的“身价”颇感兴趣。



（每个公司写2~3个核心项目就好了，如果你有非常大量的项目，那么按分类进行合并，每一类选一个典型写出来。其他的一笔带过即可。）

## 北京惟数科技有限公司 ( 2018 年 6 月 至 2018 年 7 月 )

### 中原银行-数据分析师培训 “在线实训平台” 搭建
> 技能关键词: 项目开发, Web 程序开发, jupyter notebook, pyspark, spark, python, Flask, Zeppelin

我在该项目主要负责搭建“在线数据建模分析平台”，用于支持中原银行“数据分析师”培训课程，为学员提供在线实时实验环境，供学员练习培训课程上所学到的知识点。该平台以在线开发环境 Zeppelin 为主，并结合几个我司自主研发的模块，共同构成“在线数据建模分析平台”。

在项目开始时，我使用传统的软件安装方式安装并集成整个实训平台——使用公司的百度云虚拟服务器，下载源码和各种组件进行安装。这种安装费时费力，且稍有不慎系统环境就会变的非常混乱，极大提升运维成本。多次尝试失败后，我选择使用基于 Docker 的架构。在 dockerhub 上搜索发现已经有人封装了 Zeppelin 的镜像；于是我以该镜像为原始镜像，自己撰写 Dockerfile，将该平台上所有模块集成进同一个容器中，极大简化安装及卸载工作，降低运维成本。

我的“将传统软件容器化”的做法得到了项目负责人的大力赞扬。该负责人告诉我，“容器化”是下一步软件开发的必然趋势，自己也有将公司的软件逐步封入镜像的打算，我的所作所为正是他所愿意看到的。最终该容器化的“在线实训平台”承受住了 50 余人同时在线进行数据分析练习的要求。


### 百度云智学院 “百度云ABC工程师” 高级认证
> 技能关键词: 认证考试, 云计算(百度云), 大数据、AI、云计算相关概念

公司提供的培训机会。由于公司是百度云的重要合作伙伴，因此我和其他两名同仁作为公司的特派工程师参与了由百度云智学院举办的百度云“AI + BigData + CloudComputing”( 简称“百度云ABC” )为期7天的培训。在培训中，我较为系统地巩固了人工智能、大数据和云计算领域的基本知识，并学习了基本的百度云控制台的操作方法。

在培训全部结束时，百度云智学院在北师大计算考试中心组织了严格的认证考试，考察培训中所学到的概念和百度云的上机实际操作。在此次认证考试中我以“优秀”的成绩成功通过认证并获得其“高级”认证( 认证根据考试分数分为“初级”、“中级”和“高级” )。


### 其他项目

### “惟数 Git 服务器” 的容器化
> 技能关键词: 项目优化, docker, docker hub, Linux(Ubuntu)

在此项目中我将公司现有的安装在物理主机上的 Git 服务器通过 Dockerfile 的方式封装进镜像。在封装前，我对该 Git 服务器的架构组成做了详尽的研究，并细分出了哪些部分可以放入容器( Git服务 )、哪些部分适合 bind-mount 挂载( 如用户提交的代码 )、哪些适合用 volume 挂载( 如自带的数据库数据 )、哪些服务需要暴露端口( 如主页面 )等。

在该项目完成后，负责运维的同事对我的工作予以肯定。


## 稀牛学院 ( 2018 年 4 月 至 2018 年 6 月 )

### “基于链家网的房源信息爬取” 项目
> 技能关键词: 数据获取, 数据分析, python, Scrapy, NoSQL(mongoDB), Linux(Ubuntu), git
[项目链接](https://github.com/XinyaoTian/lianjia_Spider)

该项目主要用于自动化爬取每日更新的链家网全网房源信息，并进行数据的本地持久化存储。在该项目中，我负责了一个典型爬虫项目的全部流程：从选择爬虫框架、根据网页信息设计爬虫字段及 Nosql 数据库字段，到爬虫程序的开发及部署，直至最后的定时自动化管理和云主机的基本运维。

在该项目开发完毕并部署于腾讯云主机后，每天可抓取数十万条链家网房屋的各项房屋数据，并且实现几乎完全自动化。该项目的产出结果包括两部分：存储于 MongoDB 的房源数据以及存储于 csv 文件中的数据；而存储数据的 csv 文件每天会定时自动发布到 Github 上，供有需求的数据爱好者们使用。

该项目得到了广大数据爱好者的好评，有数篇数据科学领域的技术文章中都指明了，其数据来源是本爬虫项目。该项目至今仍开源在 Github 上，供爬虫学习者们分享交流。该项目还作为网络课程“数据科学师训营”的期末结业项目，为一批又一批的数据爱好者们提供着优质的数据来源和项目源代码。

### 《Python 数据获取》在线课程的设计及开发
> 技能关键词: 课程设计, 课程开发, python, Scrapy, html, css, NoSQL(mongoDB), MySQL, Linux(Ubuntu), Jupyter notebook, git, API 等众多 python 及 scrapy 配合使用的常用工具
[全套课件讲义链接](http://proxy.smartian.net:10300/XinyaoTian/lesson_materials)


该项目是开发网络课程“Python 数据获取”的全套 ipynk 课件、配套练习的项目源代码及练习指导视频。该项目从与网校工作人员对接、明确需求，到以每三天为单位的迭代开发及改进，全部由我一个人独立负责并完成。为了保证课程的质量，我利用课余时间学习补充了大量数据获取的相关知识、阅读了大量书籍和工具文档，并积累了许多宝贵知识( 比如 Scrapy 的架构和开发方法及网页源码的解析等等 )和经验。

该项目一共 26 节课程，这些课程的所有课件、练习和指导视频我全部在规定时间内交付，并获得了对方课程产品经理的高度评价。在这个过程中我不仅学习到了知识，更重要的是，我还懂得了“清晰明确的交流沟通” 配合 “具体可执行的计划” 的重要性。程序开发绝不仅仅是写代码，它还包括了其他方方面面的事情。


### 其他经历

### 担任 “数据科学实训营-第五期” 课程班主任
> 技能关键词: 团队协作, 团队管理, 新媒体运营

利用课余时间，我在网络课程“数据科学师训营-第五期”中担任了班主任职务。该职务主要负责组织 qq 群和微信群内的学员交流和答疑活动、协调讲师的直播时间、安排课程学习进度、以及分配给助教各项任务并及时反馈。课程结束后我收到了课程负责人的肯定和学员们的热烈好评，还与讲师和许多学员、助教成为了很好的朋友，直到现在还常常一起讨论技术细节和分享生活上的点点滴滴。


---

# 校内经历


## 校内项目
为节省您宝贵的时间，在此仅列出与企业合作的、具有代表性的以及有价值的项目

### 中软国际 “铁路座位订票系统” 项目
> 技能关键词: 项目开发, 团队协作, 分布式系统, 软件测试, 持续集成, Java, SpringBoot, SQL(mySQL, DB2), NoSQL(mongoDB), Nginx, Kafka, 内存型数据库( Redis ), git, Linux(Ubuntu), html, css
项目代码及报告: [私人 Git 服务器链接](http://proxy.smartian.net:10300/XinyaoTian/Bigdata_Repository)

该项目使用 SpringBoot 作为开发框架，配合 Nginx、Kafka、Redis、MongoDB、DB2 等多种组件，开发出具有基本功能( 注册、充值、购票、退票等 )的铁路订票 Web 服务系统。作为项目组的核心开发者，我负责全部与“购票”和“退票”有关的数据库表设计、并使用 SpringBoot 框架实现了购票和退票的相关算法和全部功能逻辑。在设计购票算法时，我将已有的由哈工大同学提出的“切票”功能算法进行了改进，使之操作变得更为简单快捷。

该项目部署在 Linux 云主机上并成功运行。在该项目交付时，由于清晰的代码、健全稳定的功能逻辑和美观的页面，我们的项目获得了中软国际专家组的一致好评，并获得了 95 分( 满分 100 分 )的最高分数。在该项目评选结束后，我们的项目获得“最佳项目”的称号并作为优秀项目的典范用于中软国际其公司内部培训的参考项目。


### 李娟教授项目组 “基于 OCR 的车牌号图像识别” 项目
> 技能关键词: 项目开发, 组件开发, Java, 微软 OCR 库, 数字图像处理

该项目主要基于微软 OCR 光学识别库，为验证李娟教授的“图像识别中的‘注意力’理论”进行展开。作为项目组的一员，我主要负责利用 JAVA 编写图像预处理、二值化和降噪这三个功能的模块，并将其整合进由研究生开发出的系统中。在这三个模块通过测试并整合进系统后，图像识别的平均时间减少了 15%( 从识别原始图像到识别降噪过的图像 )，李娟老师和研究生对我的工作予以肯定。


### 星火基金项目 “基于房产交易网站的数据获取与分析” 
> 技能关键词: 数据获取, 数据分析, python, Scrapy, NoSQL(mongoDB), Linux(Ubuntu), git

本项目主要利用爬虫获取数据，并基于 PHP 进行微信小程序的制作，并在微信小程序中查看到房源的各项分析数据。在该项目中我主要负责爬虫的设计、实现和自动化部署。该项目在制作完成后获得了指导老师和评委们的肯定。




## 学业成就

### 2017 至 2018 学年( 大三学年 ) 学年成绩全学院 Top 10

### 2017 至 2018 学年( 大三学年 ) 校级&学院级 学业优秀奖学金获得者

### 2016 年 “鼎新杯-校级创新大赛” 铜奖



## 国际化 & 英语水平

### 雅思考试( IELTS )成绩 总分 6.5
其中各项小分成绩为：阅读:7.0 写作:6.5 口语:5.5 听力:6.0 

### 基本具备直接查阅英文开发文档的能力

### 基本具备直接阅读英文论文的能力

### 于大一暑假前夕通过大学英语四级( CET-4 )考试

### 校内多门双语专业课取得优秀成绩

---

# 开源项目和作品
（这一段用于放置工作以外的、可证明你的能力的材料）

## 开源项目
（对于程序员来讲，没有什么比Show me the code能有说服力了）

 - [小型高级语言编译器](https://github.com/XinyaoTian/compilation)：该项目实现了一种本人“自创语法”的高级语言的小型编译器，拥有十余种预设的关键字和类型。基于有限自动机和闭包原理，接收键盘输入并进行关键字匹配等多个步骤，最后输出可执行的三地址码。
 - [用于职位分析的中文去停用词工具库](https://github.com/XinyaoTian/ChineseTokenize/blob/master/Test_notebook.ipynb)：该项目主要供自然语言处理爱好者和开发者使用。结合了哈工大、百度等四家权威机构研究出的去停用词库，实现了操作极为简便却功能强大的中文去停用词工具库。
- [“链家网”房源获取自动化爬虫](https://github.com/XinyaoTian/lianjia_Spider)：基于 Scrapy 框架的“链家网”全网房源爬虫项目，内置自主研发的 IP 池和“获取可用 IP 的 api 接口”等实用爬虫功能，。该项目清晰的代码风格和实用的功能获得了广大数据爱好者的好评。

 
 
## 外文博客及文档翻译

本人作为“掘金翻译计划”的贡献者之一，在自己的学习过程中，会定期地将自己收藏的有价值的外文文章翻译成中文，供广大中文社区的开发者阅读，以提供便利。自从我的翻译计划从去年开始以来，知乎上已经收到了数百次感谢、收藏和点赞。


- [什么是四层(L4 proxy)和七层负载均衡(L7 proxy)?区别是什么? 翻译自Nginx官网](https://zhuanlan.zhihu.com/p/53438208)
- [Envoy 、 Nginx 和 HAProxy，微服务中的通信代理该如何抉择? 翻译自英文博客](https://zhuanlan.zhihu.com/p/53470343)
- [如何处理变化无常的容器网络位置(IP:port)?浅谈微服务架构中的服务发现。翻译自Nginx官网](https://zhuanlan.zhihu.com/p/53716019)
- [【服务网格】四种 Service Mesh 各种特性大比拼 翻译自外文博客](https://zhuanlan.zhihu.com/p/53934111)

## 技术文章

本人在知乎专栏和 csdn 社区均有多份投稿作品，下面列举出部分有代表性的文章供您参考：

- [浅谈 Service Mesh: 其定义、起源、出现背景和设计理念及作用](https://zhuanlan.zhihu.com/p/53858501)
- [K8s为何需要Istio？较为深入地讨论 Istio——其历史发展、设计理念、核心功能原理及运行流程](https://zhuanlan.zhihu.com/p/54123996)
- [5G技术分析及趋势预测——物联网前沿关键技术发展趋势分析](https://blog.csdn.net/weixin_38070561/article/details/80537615)
- [系列文章【从零开始/亲测国内外均可】基于阿里云Ubuntu的kubernetes(k8s)主从节点分布式集群搭建——分步详细攻略v1.11.3](https://blog.csdn.net/weixin_38070561/article/details/82981517)
- [K8s Rest API 研究成果&基本功能 说明文档](https://github.com/XinyaoTian/k8s_api_tutorial)
- [ pyhdfs使用指导——附代码及运行结果 ](https://blog.csdn.net/weixin_38070561/article/details/81289601)

## 演讲和讲义

 - “游历四方，初心不改”——2018 暑期实习报告会：[ppt 链接](http://proxy.smartian.net:10300/XinyaoTian/practice_ppt/raw/master/%e5%ae%9e%e4%b9%a0%e6%8a%a5%e5%91%8a.pptx)
 - “关于数据流动的圆运动”——牙周病项目公司内部报告会：[ppt 链接](http://proxy.smartian.net:10300/XinyaoTian/pku_dentist/raw/master/%e5%a4%a7%e6%95%b0%e6%8d%ae%e5%ae%9e%e8%b7%b5%e8%af%be%e7%a8%8b%e5%b1%95%e7%a4%ba%e7%89%99%e5%91%a8%e7%97%85%e6%b2%bb%e7%96%97%e6%96%b9%e6%a1%88%e7%96%97%e6%95%88%e9%a2%84%e6%b5%8b.pptx)
 - 《Python 数据获取》在线课程讲义：[全套课件讲义链接](http://proxy.smartian.net:10300/XinyaoTian/lesson_materials)

# 技能清单

以下为我基本掌握的技能: 

- 编程语言：Java(用于编写学校课程项目)/Python(用于编写自己感兴趣的程序)/Golang(用于辅助理解数据结构等计算机底层原理)
- 开发环境: Idea/PyCharm/GoLand/Zeppelin/Jupyter notebook
- 容器虚拟化：docker-ce
- 容器管理框架：Kubernetes
- 微服务架构: Istio/Envoy/Prometheus/Grafana
- 数据科学: pyspark/pyhdfs
- Web开发：SpringBoot/Flask/html/css
- 数据库相关：MySQL/MongoDB
- 消息队列: ActiveMQ/Kafka
- 数据获取相关: Scrapy/BeautifulSoup
- 版本管理、文档和自动化部署工具：Git
- 操作系统: Ubuntu 16.04
- 云和开放平台：Bandwagon/阿里云/腾讯云

## 参考技能关键字

本技能关键字列表是从最近招聘Web前端的数百份JD中统计出来的，括号中是出现的词频。如果你的简历要投递给有机器（简历分选系统）和不如机器（不懂技术的HR）筛选简历环节的地方，请一定从下边高频关键词中选择5～10个适合你自己的。

- web(889)
- javascript(596)
- css(555)
- html(430)
- jquery(323)
- html5(312)
- js(311)
- ajax(196)
- css3(176)
- w3c(168)
- div(156)
- php(134)
- xhtml(106)
- java(92)
- ui(78)
- photoshop(75)
- dom(63)
- xml(56)
- json(54)
- yui(51)
- flash(45)
- bootstrap(43)
- python(43)
- http(38)
- dreamweaver(38)
- ext(33)
- linux(33)
- seo(32)
- prototype(29)
- chrome(28)
- pc(28)
- nodejs(28)
- firefox(26)
- ps(25)
- angularjs(25)
- fireworks(24)
- extjs(23)
- safari(22)
- www(22)
- mobile(22)
- jsp(22)
- mvc(22)
- backbone(21)
- node(21)
- ruby(20)
- github(19)
- ios(18)
- ie6(18)
- android(18)
- asp(18)
- sass(17)
- wap(16)
- mootools(16)
- ie(16)
- mysql(15)
- flex(14)
- firebug(13)
- bom(13)
- webapp(12)
- less(12)
- web2(11)
- angular(10)
- git(10)
- dw(10)
- as(10)
- mac(10)
- psd(8)
- o2o(7)
- dojo(7)
- actionscript3(6)
- grunt(5)
- ue(5)
- zepto(5)
- actionscript(5)
- ie8(5)
- coffeescript(5)
- django(4)




---

# 致谢
感谢您花费宝贵时间阅读我的简历，希望本人的工作、学习能力及工作态度能够符合贵公司对于该岗位的需求。非常期待能有机会和您共事。
